# ğŸï¸ Predicting Formula 1 Race Outcomes (2022-2025)

A Data Science + Machine Learning Project on Podium Probabilities, Finishing Positions & Points

This repository contains the full code, data pipelines, models, and simulations behind my Formula 1 prediction project. Using telemetry, qualifying performance, pit strategy variables, and weather indicators from the 2022â€“2024 seasons, we built a set of machine learning models capable of:

âœ… Predicting podium probability (binary classification)

âœ… Predicting finishing position (ranked regression)

âœ… Predicting points scored (numerical regression)

âœ… Running what-if simulations (e.g., â€œHow would wind or temperature change podium chances?â€)

The project blends sports analytics, ML modeling, and real-world engineering logic from F1 racing.


â¸»

## ğŸ Project Highlights

1. Podium Classifier (Logistic Regression + Feature Engineering)
	â€¢	Predicts the probability that a driver finishes top 3.
	â€¢	Uses calibrated probabilities (Platt scaling) and an optimized decision threshold.
	â€¢	Key insight: qualifying round reached and grid position dominate predictive performance.

2. Finishing Position Model (Random Forest / XGBoost / Ordinal Regression)
	â€¢	Predicts continuous finishing scores and re-ranks drivers within each race.
	â€¢	Models evaluated with MAE, RMSE, Spearman/Kendall correlations, and Top-k accuracy.
	â€¢	Best performer for 2024 out-of-sample: Random Forest.

3. Points Prediction (Regression)
	â€¢	Parallel modeling pipeline using the official FIA scoring system.
	â€¢	Best performer: XGBoost, with strong correlation to true points earned.

4. Weather What-If Simulations
	â€¢	Adjust weather variables such as wind, temperature, pressure, and precipitation to measure model sensitivity.
	â€¢	Key insight:
	â€¢	Low air pressure increases podium probability the most across drivers.
	â€¢	Wind has mild effects, and precipitation does almost nothing in recent seasons.

5. Full Race Prediction Example: Australian GP 2025
	â€¢	Predicts podium chances, finishing positions, and points for the entire grid.
	â€¢	Used as an end-to-end evaluation of the modeling framework.

â¸»
## ğŸ Methodology Summary

	â€¢	Temporal splits (train on 2022â€“2024, test on later seasons).
	â€¢	Preprocessing via:
	â€¢	median imputation
	â€¢	z-score normalization
	â€¢	one-hot encoding for driver, constructor, circuit
	â€¢	Classification metrics: ROC-AUC, F1, lift, confusion matrix
	â€¢	Regression metrics: MAE, RMSE, RÂ², Spearman & Kendall correlations
	â€¢	Feature importance via Random Forest and SHAP values
	â€¢	Model calibration for probability realism
	â€¢	Scenario simulation engine for stress-testing weather variables

â¸»

## ğŸ Key Findings
	â€¢	Qualifying is king â€” it is by far the strongest determinant of podium probability.
	â€¢	Race execution (pit efficiency, tire life) matters more than raw lap time.
	â€¢	Weather barely affects outcomes in the recent era â€” except air pressure.
	â€¢	Machine learning can capture race dynamics, but surprise moments still belong to racing.

â¸»

## ğŸ Predictions & Interpretation

The repo includes:
	â€¢	Predicted podium chances for the 2025 season
	â€¢	Full predicted finishing orders
	â€¢	Per-driver sensitivity charts from weather simulations

These predictions are probabilistic, not deterministic. Intended to explore patterns, not claim certainty.

â¸»
## ğŸ™Œ Acknowledgments

Thanks to FastF1, Jolpica, and the incredible open-source contributors to scikit-learn, XGBoost, and SHAP.
Of courseâ€¦ thank you to F1 for giving us the most beautiful data-generating process on Earth. 

â¸»
## ğŸ‘¥ Contributors
**Carolina Rios** â€” EDA, modeling, what-if simulations, predictions, and co-author of the Medium article

**Emma Trunnell** â€” Feature extraction, data consolidation, final data analysis, and co-author of the Medium article

**Maria-Laura PeÃ±a** â€” Limitations & future work

**Abhi Pandya** â€” Abstract & introduction

**Prem Badri** â€” Feature extraction
